{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jw9FMur02UtZ"
   },
   "source": [
    "# RUL estimation UNIBO Powertools Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKxZ90kO2Uta"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import math\n",
    "import os\n",
    "import ntpath\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from importlib import reload\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM, Masking\n",
    "\n",
    "\n",
    "IS_COLAB = False\n",
    "IS_TRAINING = True\n",
    "RESULT_NAME = \"\"\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data_path = \"/content/drive/My Drive/battery-state-estimation/battery-state-estimation/\"\n",
    "else:\n",
    "    data_path = \"../../\"\n",
    "\n",
    "sys.path.append(data_path)\n",
    "from data_processing.unibo_powertools_data import UniboPowertoolsData, CycleCols\n",
    "from data_processing.model_data_handler import ModelDataHandler\n",
    "from data_processing.prepare_rul_data import RulHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfVCRISs2Utc"
   },
   "source": [
    "### Config logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2IvySBk2Utd"
   },
   "outputs": [],
   "source": [
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s [%(levelname)s]: %(message)s', level=logging.DEBUG, datefmt='%Y/%m/%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsbkwTX22Utf"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrHYRy-a2Utg"
   },
   "outputs": [],
   "source": [
    "dataset = UniboPowertoolsData(\n",
    "    test_types=[],\n",
    "    chunk_size=1000000,\n",
    "    lines=[37, 40],\n",
    "    charge_line=37,\n",
    "    discharge_line=40,\n",
    "    base_path=data_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSFp-2Rl2Utj"
   },
   "outputs": [],
   "source": [
    "train_names = [\n",
    "    '000-DM-3.0-4019-S',#minimum capacity 1.48\n",
    "    '001-DM-3.0-4019-S',#minimum capacity 1.81\n",
    "    '002-DM-3.0-4019-S',#minimum capacity 2.06\n",
    "\n",
    "    '009-DM-3.0-4019-H',#minimum capacity 1.41\n",
    "    '010-DM-3.0-4019-H',#minimum capacity 1.44\n",
    "\n",
    "    '014-DM-3.0-4019-P',#minimum capacity 1.7\n",
    "    '015-DM-3.0-4019-P',#minimum capacity 1.76\n",
    "    '016-DM-3.0-4019-P',#minimum capacity 1.56\n",
    "    '017-DM-3.0-4019-P',#minimum capacity 1.29\n",
    "    #'047-DM-3.0-4019-P',#new 1.98\n",
    "    #'049-DM-3.0-4019-P',#new 2.19\n",
    "\n",
    "\n",
    "\n",
    "    '007-EE-2.85-0820-S',#2.5\n",
    "    '008-EE-2.85-0820-S',#2.49\n",
    "    '042-EE-2.85-0820-S',#2.51\n",
    "\n",
    "    '043-EE-2.85-0820-H',#2.31\n",
    "\n",
    "\n",
    "    '040-DM-4.00-2320-S',#minimum capacity 3.75, cycles 188\n",
    "\n",
    "\n",
    "    '018-DP-2.00-1320-S',#minimum capacity 1.82\n",
    "    #'019-DP-2.00-1320-S',#minimum capacity 1.61\n",
    "    '036-DP-2.00-1720-S',#minimum capacity 1.91\n",
    "    '037-DP-2.00-1720-S',#minimum capacity 1.84\n",
    "    '038-DP-2.00-2420-S',#minimum capacity 1.854 (to 0)\n",
    "    '050-DP-2.00-4020-S',#new 1.81\n",
    "    '051-DP-2.00-4020-S',#new 1.866    \n",
    "    \n",
    "]\n",
    "\n",
    "test_names = [\n",
    "    '003-DM-3.0-4019-S',#minimum capacity 1.84\n",
    "\n",
    "    '011-DM-3.0-4019-H',#minimum capacity 1.36\n",
    "\n",
    "    '013-DM-3.0-4019-P',#minimum capacity 1.6\n",
    "\n",
    "\n",
    "\n",
    "    '006-EE-2.85-0820-S',# 2.621\n",
    "    \n",
    "    '044-EE-2.85-0820-H',# 2.43\n",
    "\n",
    "\n",
    "\n",
    "    '039-DP-2.00-2420-S',#minimum capacity 1.93\n",
    "\n",
    "\n",
    "\n",
    "    '041-DM-4.00-2320-S',#minimum capacity 3.76, cycles 190\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-yTrXQ12Utm"
   },
   "outputs": [],
   "source": [
    "dataset.prepare_data(train_names, test_names)\n",
    "dataset_handler = ModelDataHandler(dataset, [\n",
    "    CycleCols.VOLTAGE,\n",
    "    CycleCols.CURRENT,\n",
    "    CycleCols.TEMPERATURE\n",
    "])\n",
    "\n",
    "rul_handler = RulHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAAxueIqkZM9"
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPACITY_THRESHOLDS = {\n",
    "  3.0 : 2.7,#th 90% - min 2.1, 70%\n",
    "  2.85 : 2.7,#th 94.7% - min 2.622, 92%\n",
    "  2.0 : 1.93,#th 96.5% - min 1.93, 96.5%\n",
    "  4.0 : 3.77,#th 94.2% - min 3.77 94.2%\n",
    "  4.9 : 4.7,#th 95.9% - min 4.3, 87.7%\n",
    "  5.0 : 4.5#th 90% - min 3.63, 72.6%\n",
    "}\n",
    "N_CYCLE = 500\n",
    "WARMUP_TRAIN = 15\n",
    "WARMUP_TEST = 30\n",
    "\n",
    "(train_x, train_y_soh, test_x, test_y_soh,\n",
    "  train_battery_range, test_battery_range,\n",
    "  time_train, time_test, current_train, current_test) = dataset_handler.get_discharge_whole_cycle_future(train_names, test_names)\n",
    "\n",
    "train_x = train_x[:,:284,:]\n",
    "test_x = test_x[:,:284,:]\n",
    "print(\"cut train shape {}\".format(train_x.shape))\n",
    "print(\"cut test shape {}\".format(test_x.shape))\n",
    "\n",
    "train_y = rul_handler.prepare_y_future(train_names, train_battery_range, train_y_soh, current_train, time_train, CAPACITY_THRESHOLDS)\n",
    "del globals()[\"current_train\"]\n",
    "del globals()[\"time_train\"]\n",
    "test_y = rul_handler.prepare_y_future(test_names, test_battery_range, test_y_soh, current_test, time_test, CAPACITY_THRESHOLDS)\n",
    "del globals()[\"current_test\"]\n",
    "del globals()[\"time_test\"]\n",
    "\n",
    "x_norm = rul_handler.Normalization()\n",
    "train_x, test_x = x_norm.fit_and_normalize(train_x, test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compressing x using autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOENCODER_WEIGHTS = '2021-07-19-17-29-18_autoencoder_unibo_powertools'\n",
    "\n",
    "# Model definition\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "LATENT_DIM = 10\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(train_x.shape[1], train_x.shape[2])),\n",
    "            #layers.MaxPooling1D(5, padding='same'),\n",
    "            layers.Conv1D(filters=16, kernel_size=5, strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv1D(filters=8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(self.latent_dim, activation='relu')\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(self.latent_dim)),\n",
    "            layers.Dense(568, activation='relu'),\n",
    "            layers.Reshape((71, 8)),\n",
    "            layers.Conv1DTranspose(filters=8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv1DTranspose(filters=16, kernel_size=5, strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv1D(3, kernel_size=3, activation='relu', padding='same'),\n",
    "            #layers.UpSampling1D(5),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = Autoencoder(LATENT_DIM)\n",
    "autoencoder.compile(optimizer=opt, loss='mse', metrics=['mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "autoencoder.encoder.summary()\n",
    "autoencoder.decoder.summary()\n",
    "\n",
    "autoencoder.load_weights(data_path + 'results/trained_model/%s/model' % AUTOENCODER_WEIGHTS)\n",
    "\n",
    "\n",
    "# compression\n",
    "train_x = autoencoder.encoder(train_x).numpy()\n",
    "test_x = autoencoder.encoder(test_x).numpy()\n",
    "print(\"compressed train x shape {}\".format(train_x.shape))\n",
    "print(\"compressed test x shape {}\".format(test_x.shape))\n",
    "test_x = test_x[:,~np.all(train_x == 0, axis=0)]#we need same column number of training\n",
    "train_x = train_x[:,~np.all(train_x == 0, axis=0)]\n",
    "print(\"compressed train x shape without zero column {}\".format(train_x.shape))\n",
    "print(\"compressed test x shape without zero column {}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = rul_handler.Normalization()\n",
    "train_x, test_x = x_norm.fit_and_normalize(train_x, test_x)\n",
    "train_x = rul_handler.battery_life_to_time_series(train_x, N_CYCLE, train_battery_range)\n",
    "test_x = rul_handler.battery_life_to_time_series(test_x, N_CYCLE, test_battery_range)\n",
    "\n",
    "train_x, train_y, train_battery_range, train_y_soh = rul_handler.delete_initial(train_x, train_y, train_battery_range, train_y_soh, WARMUP_TRAIN)\n",
    "test_x, test_y, test_battery_range, test_y_soh = rul_handler.delete_initial(test_x, test_y, test_battery_range, test_y_soh, WARMUP_TEST)\n",
    "\n",
    "# first one is SOH, we keep only RUL\n",
    "train_y = train_y[:,1]\n",
    "test_y = test_y[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GskElnOAxTil"
   },
   "source": [
    "## Y normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EOallNnxSpQ"
   },
   "outputs": [],
   "source": [
    "y_norm = rul_handler.Normalization()\n",
    "train_y, test_y = y_norm.fit_and_normalize(train_y, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iYU-n0K2Utq"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSx96n4w2Uts"
   },
   "outputs": [],
   "source": [
    "if IS_TRAINING:\n",
    "    EXPERIMENT = \"lstm_autoencoder_rul_unibo_powertools\"\n",
    "\n",
    "    experiment_name = time.strftime(\"%Y-%m-%d-%H-%M-%S\") + '_' + EXPERIMENT\n",
    "    print(experiment_name)\n",
    "\n",
    "    # Model definition\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.000003)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Masking(input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "    model.add(LSTM(128, activation='selu',\n",
    "                    return_sequences=True,\n",
    "                    kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(LSTM(64, activation='selu', return_sequences=False,\n",
    "                    kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(64, activation='selu', kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(32, activation='selu', kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=opt, loss='huber', metrics=['mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIEcv6Ey2Utu"
   },
   "outputs": [],
   "source": [
    "if IS_TRAINING:\n",
    "    history = model.fit(train_x, train_y, \n",
    "                                epochs=500, \n",
    "                                batch_size=32, \n",
    "                                verbose=1,\n",
    "                                validation_split=0\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNHlqcvP2Utx"
   },
   "outputs": [],
   "source": [
    "if IS_TRAINING:\n",
    "    model.save(data_path + 'results/trained_model/%s.h5' % experiment_name)\n",
    "\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_csv_file = data_path + 'results/trained_model/%s_history.csv' % experiment_name\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    history = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_TRAINING:\n",
    "    history = pd.read_csv(data_path + 'results/trained_model/%s_history.csv' % RESULT_NAME)\n",
    "    model = keras.models.load_model(data_path + 'results/trained_model/%s.h5' % RESULT_NAME)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_TRAINING:\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH5RANQIEQVx"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggNKW-VqENFN"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(test_x, test_y, return_dict = True)\n",
    "print(results)\n",
    "max_rmse = 0\n",
    "for index in range(test_x.shape[0]):\n",
    "    result = model.evaluate(np.array([test_x[index, :, :]]), np.array([test_y[index]]), return_dict = True, verbose=0)\n",
    "    max_rmse = max(max_rmse, result['rmse'])\n",
    "print(\"Max rmse: {}\".format(max_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiqyD8Bn2Utz"
   },
   "source": [
    "# Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jH9RrBRN2Utz"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=history['loss'],\n",
    "                    mode='lines', name='train'))\n",
    "if 'val_loss' in history:\n",
    "    fig.add_trace(go.Scatter(y=history['val_loss'],\n",
    "                    mode='lines', name='validation'))\n",
    "fig.update_layout(title='Loss trend',\n",
    "                  xaxis_title='epoch',\n",
    "                  yaxis_title='loss',\n",
    "                  width=1400,\n",
    "                  height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtLOteXd-d6n"
   },
   "outputs": [],
   "source": [
    "train_predictions = model.predict(train_x)\n",
    "\n",
    "train_y = y_norm.denormalize(train_y)\n",
    "train_predictions = y_norm.denormalize(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsYMPQ0i2Ut1"
   },
   "outputs": [],
   "source": [
    "a = 0\n",
    "for b in train_battery_range:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=train_y_soh[a:b], y=train_predictions[a:b,0],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(x=train_y_soh[a:b], y=train_y[a:b],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on training',\n",
    "                    xaxis_title='SoH Capacity',\n",
    "                    yaxis_title='Remaining Ah until EOL',\n",
    "                    xaxis={'autorange':'reversed'},\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()\n",
    "    a = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pe1Pzp04J1b5"
   },
   "outputs": [],
   "source": [
    "a = 0\n",
    "for b in train_battery_range:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=train_predictions[a:b,0],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=train_y[a:b],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on training',\n",
    "                    xaxis_title='Cycle',\n",
    "                    yaxis_title='Remaining Ah until EOL',\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()\n",
    "    a = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0olyqr4-8BG"
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_x)\n",
    "\n",
    "test_y = y_norm.denormalize(test_y)\n",
    "test_predictions = y_norm.denormalize(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9U1MbGnq2Ut4"
   },
   "outputs": [],
   "source": [
    "a = 0\n",
    "for b in test_battery_range:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=test_y_soh[a:b], y=test_predictions[a:b,0],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(x = test_y_soh[a:b], y=test_y[a:b],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on testing',\n",
    "                    xaxis_title='SoH Capacity',\n",
    "                    yaxis_title='Remaining Ah until EOL',\n",
    "                    xaxis={'autorange':'reversed'},\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()\n",
    "    a = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLEl8nALKAgJ"
   },
   "outputs": [],
   "source": [
    "a = 0\n",
    "for b in test_battery_range:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=test_predictions[a:b, 0],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=test_y[a:b],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on testing',\n",
    "                    xaxis_title='Cycle',\n",
    "                    yaxis_title='Remaining Ah until EOL',\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()\n",
    "    a = b"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_soh_prediction_only_future.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
